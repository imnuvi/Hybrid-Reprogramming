{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d66edda-5927-439c-84a5-332328ae64f1",
   "metadata": {},
   "source": [
    "# Pipeline for processing CZI files and segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6650b6f0-afc2-4cec-8ea3-ddebf302a7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "from aicspylibczi import CziFile\n",
    "from pathlib import Path\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import xml.dom.minidom\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, ListedColormap\n",
    "\n",
    "from PIL import Image\n",
    "from skimage import filters, segmentation, morphology, color, exposure, restoration, measure, feature\n",
    "from skimage.measure import regionprops_table\n",
    "from skimage.filters import threshold_otsu, threshold_triangle, threshold_local\n",
    "\n",
    "from sklearn import preprocessing as p\n",
    "from skimage.segmentation import find_boundaries\n",
    "from skimage.measure import regionprops, label\n",
    "\n",
    "\n",
    "from stardist.models import StarDist2D\n",
    "from csbdeep.utils import normalize\n",
    "\n",
    "from scipy import ndimage\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d02d0fa-d135-44e1-b750-2da6539f00e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from skimage import io\n",
    "from btrack import datasets\n",
    "import btrack\n",
    "import tifffile\n",
    "import napari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81d49c0-5323-43ae-8814-41dee133a7ac",
   "metadata": {},
   "source": [
    "\n",
    "#### 2024-12-21-PRRX1-MYOD-3-01.czi\n",
    "- This is 0-24 hours (according to the timeline below)\n",
    "- 68 time points, 20 min intervals\n",
    "- Note that the 68th time point is messed up and should be removed\n",
    "- Size: 113.2 GB\n",
    "\n",
    "#### 2024-12-22-PRRX1-MYOD-3-02.czi\n",
    "This is 24-72 hours (according to the timeline below)\n",
    "137 time points, 20 min intervals\n",
    "Size: 231.5 GB\n",
    "\n",
    "#### Scenes:\n",
    "These czi's both contain 18 scenes, some with and without the nuclear stain (SiR-DNA). For analysis, we are only interested in the scenes with SiR-DNA. Those scenes (and their respective conditions) are described here:\n",
    "- Cells only (negative control): s1, s7, s13\n",
    "- PRRX1 only: s2, s3\n",
    "- MYOD1 only: s14, s15\n",
    "- PRRX1+MYOD1: s8, s9, s11\n",
    "\n",
    "#### Channel order:\n",
    "- TagGFP (Green)\n",
    "- mKate (Red)\n",
    "- Cy5 (Nuclear stain)\n",
    "- Oblique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb1ed7da-dab2-4cdc-8012-3673f6bd6b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "def norm_by(x, min_, max_):\n",
    "    \"\"\"\n",
    "    normalization function, taking in a percentile range to clip\n",
    "    \n",
    "    :param x: 2d numpy array to be normalized\n",
    "    :type x: 2d numpy array\n",
    "    \n",
    "    :param min_: Minimum percentile to clip out\n",
    "    :type min_: int (0-100)\n",
    "    \n",
    "    :param max_: Maximum percentile to clip out\n",
    "    :type max_: int (0-100)\n",
    "    \n",
    "    :return: 3 channel cmy image\n",
    "    :rtype: 3 mode numpy array\n",
    "    \"\"\"\n",
    "    norms = np.percentile(x, [min_, max_])\n",
    "    i2 = np.clip((x - norms[0]) / (norms[1] - norms[0]), 0, 1)\n",
    "    return i2\n",
    "\n",
    "\n",
    "def recolor(im):\n",
    "    \"\"\"\n",
    "    given an rgb image, convert to cyan-magenta-yellow\n",
    "    :param im: 3 channel image\n",
    "    :type im: 3 mode numpy array\n",
    "    \n",
    "    :return: 3 channel cmy image\n",
    "    :rtype: 3 mode numpy array\n",
    "    \"\"\"\n",
    "    im_shape = np.array(im.shape)\n",
    "    color_transform = np.array([[1, 1, 0], [0, 1, 1], [1, 0, 1]]).T\n",
    "    im_reshape = im.reshape([np.prod(im_shape[0:2]), im_shape[2]]).T\n",
    "    im_recolored = np.matmul(color_transform.T, im_reshape).T\n",
    "    im_shape[2] = 3\n",
    "    im = im_recolored.reshape(im_shape)\n",
    "    return im\n",
    "\n",
    "def merge_channels(channel1, channel2, weights=(0.5, 0.5)):\n",
    "    \"\"\"\n",
    "    Given 2 2d arrays, merge them with a certain weight factor\n",
    "    \n",
    "    :param channel1: first channel to be merged\n",
    "    :type channel1: 2d numpy array\n",
    "\n",
    "    :param channel2: first channel to be merged\n",
    "    :type channel2: 2d numpy array\n",
    "\n",
    "    :param channel1: percentage to merge the channels\n",
    "    :type channel1: set of ints\n",
    "    \n",
    "    :return: merged channel based on the weights\n",
    "    :rtype: 2d numpy array\n",
    "    \"\"\"\n",
    "    if channel1.shape != channel2.shape:\n",
    "        raise ValueError(\"Channels must have the same dimensions.\")\n",
    "\n",
    "    if len(weights) != 2:\n",
    "         raise ValueError(\"Weights must be a tuple of length 2.\")\n",
    "\n",
    "    merged_channel = (weights[0] * channel1) + (weights[1] * channel2)\n",
    "    return merged_channel\n",
    "    \n",
    "def plot_mosaic(c1, c2, c3, plot=True):\n",
    "    \"\"\"\n",
    "    Helper to normalize raw channels from mosaic tiles and optionally plot them\n",
    "    \n",
    "    :param c1, c2, c3: channel arrays\n",
    "    :type c1, c2, c3: 2d numpy array\n",
    "\n",
    "    :param plot: Optional flag to plot the image\n",
    "    :type plot: bool\n",
    "    \n",
    "    :return: Returns all the normalized channels\n",
    "    :rtype: set(numpy.array)\n",
    "    \"\"\"\n",
    "    scalex = 471\n",
    "    scaley = 649\n",
    "\n",
    "    timex = (scalex) * 2\n",
    "    timey = (scaley) * 2\n",
    "    c1 = (norm_by(c1[0, 0, 0, 0:timex, 0:timey], 50, 99.8) * 255).astype(np.uint8)\n",
    "    c2 = (norm_by(c2[0, 0, 0, 0:timex, 0:timey], 50, 99.8) * 255).astype(np.uint8)\n",
    "    c3 = (norm_by(c3[0, 0, 0, 0:timex, 0:timey], 50, 99.8) * 255).astype(np.uint8)\n",
    "    c5 = merge_channels(c1, c2)\n",
    "\n",
    "    # stacked full color image\n",
    "    rgb = np.stack((c1, c2, c3), axis=2)\n",
    "\n",
    "    # Channel wise plot\n",
    "    if plot:\n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 10))\n",
    "        axes[0].imshow(c1)\n",
    "        axes[1].imshow(c2)\n",
    "        axes[2].imshow(c3)\n",
    "        axes[3].imshow(c5)\n",
    "    \n",
    "        axes[0].set_title('Channel 1')\n",
    "        axes[1].set_title('Channel 2')\n",
    "        axes[2].set_title('Channel 3')\n",
    "        axes[3].set_title('Channel 5')\n",
    "    \n",
    "    return (c1, c2, c3, c5, rgb)\n",
    "\n",
    "    \n",
    "def plot_image(img, plot=False):\n",
    "    \"\"\"\n",
    "    Helper to normalize raw channels and optionally plot them\n",
    "    \n",
    "    :param img: the image to be plotted as a numpy array\n",
    "    :type img: 3 mode numpy array\n",
    "\n",
    "    :param plot: Optional flag to plot the image\n",
    "    :type plot: bool\n",
    "    \n",
    "    :return: merged channel based on the weights\n",
    "    :rtype: set(numpy.array)\n",
    "    \"\"\"\n",
    "    \n",
    "    c1 = (norm_by(img[ 0, ::, ::], 50, 99.8) * 255).astype(np.uint8)\n",
    "    c2 = (norm_by(img[ 1, ::, ::], 50, 99.8) * 255).astype(np.uint8)\n",
    "    c3 = (norm_by(img[ 2, ::, ::], 50, 99.8) * 255).astype(np.uint8)\n",
    "    c4 = (norm_by(img[ 3, ::, ::], 0, 100) * 255).astype(np.uint8)\n",
    "    c5 = merge_channels(c1, c2)\n",
    "    \n",
    "    rgb = np.stack((c1, c2, c3), axis=2)\n",
    "\n",
    "    # Channel wise plot\n",
    "    if plot:\n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(10, 10))\n",
    "        axes[0].imshow(c1)\n",
    "        axes[1].imshow(c2)\n",
    "        axes[2].imshow(c3)\n",
    "        axes[3].imshow(c4)\n",
    "        axes[4].imshow(c5)\n",
    "    \n",
    "        axes[0].set_title('Channel 1')\n",
    "        axes[1].set_title('Channel 2')\n",
    "        axes[2].set_title('Channel 3')\n",
    "        axes[3].set_title('Channel 4')\n",
    "        axes[4].set_title('Channel 5')\n",
    "    \n",
    "    return (c1, c2, c3, c4, c5, rgb)\n",
    "\n",
    "def convert_to_rgb(values, col):\n",
    "    zeroes = np.zeros_like(values, dtype=float)\n",
    "    if col.lower() == 'r':\n",
    "        conv = np.array([values, zeroes, zeroes], dtype=float)\n",
    "    elif col.lower() =='g':\n",
    "        conv = np.array([zeroes, values, zeroes], dtype=float)\n",
    "    elif col.lower() =='b':\n",
    "        conv = np.array([zeroes, zeroes, values], dtype=float)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8af94acf-1d38-444a-a6c5-1621e9017c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mostly for mosaic images.\n",
    "\n",
    "class Cell():\n",
    "    def __init__(self, centre):\n",
    "        pass\n",
    "\n",
    "    def track_over_time():\n",
    "        pass\n",
    "\n",
    "class Frame():\n",
    "    \"\"\"\n",
    "    Class representing a single frame from the timelapse video\n",
    "\n",
    "    :param image: actual image frame as a 3 mode numpy array\n",
    "    :type image: 3d numpy array\n",
    "\n",
    "    :param frame_num: order of the frame in the entire movie\n",
    "    :type frame_num: int\n",
    "    \n",
    "    :param plot: Optionally plot the image.\n",
    "    :type plot: bool\n",
    "    \n",
    "    :param save: save mask labels as tiff files\n",
    "    :type save: bool\n",
    "\n",
    "    Methods:\n",
    "    :function channel_runner: performs channel specefic tasks eg. counting cells\n",
    "    :function get_channel_counts: gets the count of cells in a specific channel\n",
    "    :function segmenter: core image processing function runs basic workflow on the image and generates data for furnther tasks\n",
    "    :function get_properties: Fetches the basic properties from the mask label\n",
    "    :function fetch_centroids: fetches centroids for the frame\n",
    "    :function fetch_labels: fetches labels from the properties dictionary \n",
    "    :function track_next_frame: Tracks cells across two given frames\n",
    "    \"\"\"\n",
    "    def __init__(self, image, frame_num, plot=False, save=False):\n",
    "        self.image = image\n",
    "        self.plot = plot\n",
    "        self.save = save\n",
    "        self.taggfp, self.mkate, self.cy5, self.oblique, self.taggfp_mkate, self.full_rg = image\n",
    "        self.active_channel = self.taggfp_mkate\n",
    "        self.threshold = 1e5\n",
    "        self.max_distance=50\n",
    "        self.og_frame = frame_num\n",
    "        self.frame_num = frame_num\n",
    "        self.cells = []\n",
    "        _, self.mask_labels, self.binary_labels = self.segmenter(self.active_channel)\n",
    "        self.properties = regionprops_table(\n",
    "            self.mask_labels, \n",
    "            properties=('label', 'centroid', 'area', 'bbox')\n",
    "        ) \n",
    "        self.props = measure.regionprops(self.binary_labels)\n",
    "        self.ycenters, self.xcenters, self.centroids = self.fetch_centroids(self.properties)\n",
    "        self.cell_count = label(self.binary_labels).max()\n",
    "        \n",
    "        self.labels = self.fetch_labels()\n",
    "        \n",
    "    def channel_runner(self):\n",
    "        \"\"\"\n",
    "        Helper that takes all channels and runs specified functions on them.\n",
    "\n",
    "        :return: returns metrics for each channel\n",
    "        :rtype: set of channel metrics\n",
    "        \"\"\"\n",
    "        self.save = True\n",
    "        self.plot = False\n",
    "        self.frame_num = str(self.og_frame) + '_taggfp'\n",
    "        taggfp_count = self.get_channel_counts(self.taggfp)\n",
    "        \n",
    "        self.frame_num = str(self.og_frame) + '_mkate'\n",
    "        mkate_count = self.get_channel_counts(self.mkate)\n",
    "        \n",
    "        self.frame_num = str(self.og_frame) + '_cy5'\n",
    "        cy5_count = self.get_channel_counts(self.cy5)\n",
    "        \n",
    "        self.frame_num = str(self.og_frame) + '_total'\n",
    "        tag_mkate_count = self.get_channel_counts(self.taggfp_mkate)\n",
    "        \n",
    "        return taggfp_count, mkate_count, cy5_count, tag_mkate_count\n",
    "\n",
    "    def get_channel_counts(self, channel):\n",
    "        \"\"\"\n",
    "        Counts number of cells in the channel\n",
    "        \n",
    "        :param channel: channel to be processed\n",
    "        :type channel: 2d array\n",
    "         \n",
    "        :return: count of cells in the array\n",
    "        :rtype: int\n",
    "        \"\"\"\n",
    "        _, mask_labels, binary_labels = self.segmenter(channel)\n",
    "        properties = regionprops_table(\n",
    "            mask_labels, \n",
    "            properties=('label', 'centroid', 'area', 'bbox')\n",
    "        ) \n",
    "        props = measure.regionprops(binary_labels)\n",
    "        ycenters, xcenters, centroids = self.fetch_centroids(properties)\n",
    "        # self.cell_count = len(self.properties['area'])\n",
    "        cell_count = label(binary_labels).max()\n",
    "        return cell_count\n",
    "    \n",
    "    \n",
    "    def segmenter(self, channel):\n",
    "        \"\"\"\n",
    "        Core segmentation processor. Runs image processing filters and thresholding to separate out cells as foreground and the noise as background\n",
    "\n",
    "        :param channel: the channel as a 2d array\n",
    "        :type channel: numpy 2d array\n",
    "\n",
    "        :return: (processed image, raw labels, and thresholded binary labels)\n",
    "        :rtype: set(numupy.2darray)\n",
    "        \"\"\"\n",
    "        # Segnemnts channels into separate cells.\n",
    "    \n",
    "        min_max_scaler = p.Normalizer()\n",
    "        normalizedData = min_max_scaler.fit_transform(channel)\n",
    "        \n",
    "        processed = normalizedData\n",
    "        blurred = filters.gaussian(processed, sigma=2)\n",
    "    \n",
    "        thresh = blurred > filters.threshold_otsu(blurred)\n",
    "    \n",
    "        cleaned = morphology.remove_small_objects(thresh, min_size=50)\n",
    "        \n",
    "        \n",
    "        \n",
    "        distance = ndimage.distance_transform_edt(cleaned)\n",
    "        coords = feature.peak_local_max(distance, labels=cleaned)\n",
    "        mask = np.zeros(distance.shape, dtype=bool)\n",
    "        mask[tuple(coords.T)] = True\n",
    "        markers = measure.label(mask)\n",
    "        labels = segmentation.watershed(-distance, markers, mask=cleaned)\n",
    "        \n",
    "        segmented_overlay = color.label2rgb(\n",
    "            labels, \n",
    "            image=channel, \n",
    "            bg_label=0,\n",
    "            alpha=0.3,\n",
    "            colors=['cyan', 'yellow', 'magenta']  # Custom colors for labels\n",
    "        )\n",
    "\n",
    "        boundaries = find_boundaries(labels, mode='inner')\n",
    "        labelcp = copy.deepcopy(labels)\n",
    "\n",
    "        labels[labels > 1] = 1\n",
    "\n",
    "        # #Blue\n",
    "        # cmap = ListedColormap(['none', '#4529ff'])\n",
    "        # Bright grey\n",
    "        cmap = ListedColormap(['none', '#deffef'])\n",
    "\n",
    "        if self.plot:\n",
    "            print('plotting')\n",
    "            fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 10))\n",
    "            \n",
    "            for i in axes:\n",
    "                i.axis('off')\n",
    "            axes[0].imshow(channel)\n",
    "            axes[0].set_title('Channel')\n",
    "            \n",
    "            axes[1].imshow(processed)\n",
    "            axes[1].set_title('Normalized Channel')\n",
    "            \n",
    "            axes[2].imshow(labelcp, cmap='nipy_spectral')\n",
    "            axes[2].set_title('Better colored Labels')\n",
    "            \n",
    "            axes[3].imshow(channel, cmap='grey')\n",
    "            axes[3].imshow(labels, cmap=cmap, alpha=0.7)\n",
    "            axes[3].set_title('Overlay of segments')\n",
    "\n",
    "            if self.save:\n",
    "                axes[3].figure.savefig(f\"figures/Frame_segmentation_{self.frame_num}.png\")\n",
    "        return processed, labelcp, labels\n",
    "\n",
    "    def get_properties(self):\n",
    "        \"\"\"\n",
    "        Fetch segmentation properties such as 'label', 'centroid-0', 'centroid-1', 'area', 'bbox-0', 'bbox-1', 'bbox-2', 'bbox-3'\n",
    "        \"\"\"\n",
    "        return self.properties\n",
    "    \n",
    "    def fetch_centroids(self, props):\n",
    "        \"\"\"\n",
    "        fetch segmentation centroids\n",
    "        \"\"\"\n",
    "        centroid_rows = props['centroid-0']\n",
    "        centroid_columns = props['centroid-1']\n",
    "        return centroid_rows, centroid_columns, np.array(list(zip(centroid_rows, centroid_columns)))\n",
    "\n",
    "    def fetch_labels(self):\n",
    "        \"\"\"\n",
    "        Fetch segmentation labels from the properties object\n",
    "        \"\"\"\n",
    "        labels = self.properties['label']\n",
    "        return labels\n",
    "        \n",
    "    def track_next_frame(self, next_frame):\n",
    "        \"\"\"\n",
    "        Use Btrack to track the next frame segments\n",
    "        \"\"\"\n",
    "        objects = btrack.utils.segmentation_to_objects(\n",
    "                      seg, properties=('area', )\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f050837-1297-4f8f-9b19-7e473569a7b0",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d144b3-edde-4f65-8045-981baa2e0866",
   "metadata": {},
   "source": [
    "### Loading from Kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b631919-9ece-46ac-90fd-995e8e580e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running frame 2\n",
      "running frame 3\n",
      "running frame 4\n",
      "running frame 5\n",
      "running frame 6\n",
      "running frame 7\n",
      "running frame 8\n",
      "running frame 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(588, 655, 594, 731),\n",
       " (568, 654, 573, 735),\n",
       " (556, 665, 589, 740),\n",
       " (571, 651, 560, 729),\n",
       " (563, 648, 598, 731),\n",
       " (570, 660, 610, 725),\n",
       " (537, 653, 601, 726),\n",
       " (560, 677, 574, 727)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class HybridReprogramming():\n",
    "    \"\"\"\n",
    "    Dataloader class for interacting with the published dataset\n",
    "\n",
    "    :param sample: The sample of the experiment you want to load\n",
    "    :type sample: str\n",
    "    \n",
    "    :param sampleID: The sample Id within the experimental sample\n",
    "    :type sampleID: int\n",
    "\n",
    "    \n",
    "    :param basepath: The Basepath where the dataset is loaded from kaggle\n",
    "    :type basepath: path\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, sample, sampleID, basepath):\n",
    "        self.sample = sample\n",
    "        self.sampleID = sampleID\n",
    "        self.channels = 3\n",
    "        self.basepath = basepath\n",
    "\n",
    "    def load_Genexpression(self):\n",
    "        \"\"\"\n",
    "        Load the genexpression dataset into an anndata object\n",
    "\n",
    "        :return: The fully loaded anndata object to be used with scanpy\n",
    "        :rtype: anndata\n",
    "        \"\"\"\n",
    "        filepath = f'{self.basepath}/GeneExpression/Genexpression.h5ad'\n",
    "        anndata = sc.read_h5ad(filepath)\n",
    "        return anndata\n",
    "\n",
    "    def load_frames(self, time_start, time_end):\n",
    "        \"\"\"\n",
    "        Method to load the imaging data\n",
    "\n",
    "        :param time_start: The starting timepoint where the data should be loaded for\n",
    "        :type time_start: int\n",
    "\n",
    "        :param time_start: The end timepoint for the data to be loaded\n",
    "        :type time_start: int\n",
    "        \n",
    "        :return: returns the frames as a stack for the given time start and end ranges\n",
    "        :rtype: np.array()\n",
    "        \"\"\"\n",
    "        frames = []\n",
    "        for t in range(time_start, time_end):\n",
    "            filepath = f'{self.basepath}/Imaging/Imaging/{self.sample}/{self.sampleID}/t_{t+1}.hdf5'\n",
    "            f = h5py.File(filepath, 'r')\n",
    "            frame_shape = f['Scene'].shape\n",
    "            frame = f['Scene'][:]\n",
    "            frames.append(frame)\n",
    "        framestack = np.stack(frames, axis=0)\n",
    "        return framestack\n",
    "\n",
    "def masks_to_btrack_objects(exp):\n",
    "    \"\"\"\n",
    "    Converts the generated masks into btrack objects. \n",
    "\n",
    "    :param exp: The experiment object that loads in the required data\n",
    "    :type exp: HybridReprogramming\n",
    "\n",
    "    :return: The btrack objects\n",
    "    :rtype: list(btrack objects)\n",
    "    \n",
    "    \"\"\"\n",
    "    objects = []\n",
    "    for t, frame in enumerate(exp.frame_list):\n",
    "        fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        # ax.imshow(frame.binary_labels)\n",
    "        mask = frame.mask_labels\n",
    "        props = regionprops(mask)\n",
    "        for obj in props:\n",
    "            y, x = obj.centroid \n",
    "            objects.append({\n",
    "                'ID': obj.label,  \n",
    "                't': t,           \n",
    "                'x': x,            \n",
    "                'y': y,             \n",
    "                'z': 0,             \n",
    "                'prob': 1.0,       \n",
    "                'states': 0,\n",
    "                'area': obj.area,\n",
    "            })\n",
    "    return objects\n",
    "\n",
    "def tracks_to_csv(tracks):\n",
    "    \"\"\"\n",
    "    Converts the btrack tracks to csv files that can be exported or loaded elsewhere\n",
    "    :param tracks: Btrack tracks to be converted\n",
    "    :type tracks: Btrak.track\n",
    "\n",
    "    :return: None, creates a csv file with the track data\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame([{\n",
    "        'track_id': track.ID,\n",
    "        't': track.t,\n",
    "        'x': track.x,\n",
    "        'y': track.y,\n",
    "        'parent': track.parent,\n",
    "        'root': track.root,\n",
    "    } for track in tracks])\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv('cell_tracks.csv', index=False)\n",
    "\n",
    "def run_experiment(sample, sampleid, t1=1, t2=10):\n",
    "    \"\"\"\n",
    "    Helper function that loads in the experiment and runs segmentation, tracking and saves outputs to specified locations\n",
    "\n",
    "    :param sample: The sample of the experiment you want to load\n",
    "    :type sample: str\n",
    "    \n",
    "    :param sampleID: The sample Id within the experimental sample\n",
    "    :type sampleID: int\n",
    "\n",
    "    :param t1: The starting timepoint where the data should be loaded for\n",
    "    :type time_start: int\n",
    "\n",
    "    :param t2: The end timepoint for the data to be loaded\n",
    "    :type time_start: int\n",
    "\n",
    "    :return: Returrns the cell counts in each frame after saving outputs to the specified locations\n",
    "    :rtype: set(int)\n",
    "    \n",
    "    \"\"\"\n",
    "    path = '/scratch/indikar_root/indikar1/shared_data/HYB/kaggle_dataset/datasets/thedoodler/hybrid-imaging-and-genex-dataset-hyb-imagen/versions/3'\n",
    "    basepath = 'data'\n",
    "    reprogramming = HybridReprogramming(sample, sampleid, path)\n",
    "    \n",
    "    # TagGFP : Green\n",
    "    # MKate : Red\n",
    "    # Cy5 : Blue\n",
    "    \n",
    "    channelmap = {\"TagGFP\": 0, \"MKate\": 1, \"Cy5\": 2, \"Oblique\": 3}\n",
    "    frames = reprogramming.load_frames(t1, t2)\n",
    "    \n",
    "    timepoints, channels, shapex, shapey = frames.shape\n",
    "    \n",
    "    mapshapex, mapshapey = shapex//6, shapey//5\n",
    "    \n",
    "    cell_counts = []\n",
    "    for i in range(1, timepoints):\n",
    "        t = t1 + i\n",
    "        print(f'running frame {t}')\n",
    "        image = frames[i]\n",
    "        nimage = plot_image(image)\n",
    "        frame = Frame(nimage, t, plot=False)\n",
    "\n",
    "        \n",
    "        np.save(f\"{basepath}/{sample}_{sampleid}_mask_t{t}.npy\" ,frame.binary_labels)\n",
    "        counters = frame.channel_runner()\n",
    "        cell_counts.append(counters)\n",
    "        # Save original images\n",
    "\n",
    "        # Masks\n",
    "        img = frame.active_channel\n",
    "        mask = frame.binary_labels\n",
    "        \n",
    "        # fig, ax = plt.subplots(figsize=(10, 10))\n",
    "        # ax.imshow(mask)\n",
    "        \n",
    "        tifffile.imwrite(\n",
    "            f'original_images/frame_{t:03d}.tif',\n",
    "            img.astype(np.uint16),  # Use uint16 for microscopy data\n",
    "            metadata={'axes': 'YX'},  # Add metadata for clarity\n",
    "        )\n",
    "    \n",
    "        tifffile.imwrite(\n",
    "            f'segmentation_masks/mask_{t:03d}.tif',\n",
    "            mask.astype(np.uint16),\n",
    "            metadata={'axes': 'YX', 'mode': 'labels'},  # Optional metadata\n",
    "        )\n",
    "    \n",
    "\n",
    "    \n",
    "    basecountpath = 'data'\n",
    "    with open(f\"{basecountpath}/{sample}_{sampleid}_counts_136_202.txt\", \"w\") as file:\n",
    "        for item in cell_counts:\n",
    "            file.write(str(item) + \"\\n\")\n",
    "    # print(sample, sampleid, cell_counts)\n",
    "    return cell_counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6bcfdf-2762-4f0d-a504-3de53bf5a0ec",
   "metadata": {},
   "source": [
    "# Running the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bba547-7c95-46a9-830f-dc9e9a408ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run_experiment('Myod', 1)\n",
    "#run_experiment('Myod', 2)\n",
    "#run_experiment('PRRX1', 1)\n",
    "#run_experiment('PRRX1', 2)\n",
    "#run_experiment('Myod_PRRX1', 1)\n",
    "#run_experiment('Myod_PRRX1', 2)\n",
    "#run_experiment('Myod_PRRX1', 3)\n",
    "#run_experiment('Negative_Controls', 1)\n",
    "#run_experiment('Negative_Controls', 2)\n",
    "#run_experiment('Negative_Controls', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863afdc-2ca8-4911-bb3f-c7a18b6c07e2",
   "metadata": {},
   "source": [
    "### Loading from raw czi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72da9fa8-ab28-4728-a764-a2bdaf3c62cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "czi_0_24_hours = '2024-12-21-PRRX1-MYOD-3-01.czi'\n",
    "czi_24_72_hours = '2024-12-22-PRRX1-MYOD-3-02.czi'\n",
    "\n",
    "\n",
    "base_pth = Path(\"/scratch/indikar_root/indikar1/shared_data/imaging_test/full_CZIs\")\n",
    "\n",
    "\n",
    "\n",
    "pth = base_pth / czi_0_24_hours\n",
    "\n",
    "czi = CziFile(pth)\n",
    "\n",
    "metadata = czi.meta\n",
    "\n",
    "# Get the shape of the data, the coordinate pairs are (start index, size)\n",
    "dimensions = czi.get_dims_shape()\n",
    "\n",
    "my_dims = czi.dims\n",
    "\n",
    "my_size = czi.size\n",
    "\n",
    "is_mosaic = czi.is_mosaic()\n",
    "\n",
    "x = dimensions[0]['X'][1]\n",
    "y = dimensions[0]['Y'][1]\n",
    "timepoints = dimensions[0]['T'][1] - 1\n",
    "\n",
    "current_img = czi.read_mosaic(C=2, T=1, Z=0, scale_factor = 0.5)\n",
    "\n",
    "proc_img = current_img[0, 0, 0, :, :]\n",
    "\n",
    "# # print the full metadata tree\n",
    "# for elem in metadata.iter():\n",
    "#     # Print tag names and values\n",
    "#     print(elem.tag, elem.text)  \n",
    "\n",
    "print(proc_img.shape)\n",
    "# fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# ax.imshow(proc_img[:1000,:1000])\n",
    "\n",
    "img, shp = czi.read_image(S=1, Z=0, T=1, M=1)\n",
    "\n",
    "print('Is Mosaic file: ', czi.is_mosaic())\n",
    "print(dimensions)\n",
    "print(my_dims)\n",
    "print(my_size)\n",
    "print(shp)\n",
    "print(img.shape)\n",
    "\n",
    "timepoints = dimensions[0]['T'][1]\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    img, shp = czi.read_image(S=1, Z=0, T=i*3, M=1)\n",
    "    taggfp, mkate, cy5, oblique, taggfp_mkate, cur_rgb = plot_image(img)\n",
    "    plot_image(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a111dbb7-d9ed-4a9b-b659-5f3511989cd8",
   "metadata": {},
   "source": [
    "# Tracking\n",
    "### reloading saved tifffiles into memory for tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4862b124-6eac-413e-979f-55e7e22afdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload tifffiles back\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "\n",
    "\n",
    "# num_frames = 66\n",
    "num_frames = 60\n",
    "# num_frames = 30\n",
    "\n",
    "original_cy5_imgs = [\n",
    "    io.imread(f'mosaic_tiffs/original/{t}_cy5.tif')\n",
    "    for t in range(1, num_frames)\n",
    "]\n",
    "\n",
    "original_mkate_imgs = [\n",
    "    io.imread(f'mosaic_tiffs/original/{t}_mkate.tif')\n",
    "    for t in range(1, num_frames)\n",
    "]\n",
    "\n",
    "cy5_segmentation_masks = [\n",
    "    io.imread(f'mosaic_tiffs/segmentation/{t}_cy5.tif')\n",
    "    for t in range(1, num_frames)\n",
    "]\n",
    "\n",
    "graphs = [\n",
    "    io.imread(f'mosaic_graphs/{t}.png')\n",
    "    for t in range(1, num_frames)\n",
    "]\n",
    "\n",
    "imagexshape, imageyshape = original_cy5_imgs[0].shape\n",
    "\n",
    "# Convert to numpy arrays\n",
    "original_imgs = np.stack(original_cy5_imgs)\n",
    "# original_imgs = np.stack(original_mkate_imgs)\n",
    "segmentation_masks = np.stack(cy5_segmentation_masks)\n",
    "\n",
    "segmentation = segmentation_masks\n",
    "\n",
    "# for i in range(num_frames):\n",
    "#     img = original_cy5_imgs[i]\n",
    "#     mask = cy5_segmentation_masks[i]\n",
    "#     fig, ax = plt.subplots(figsize=(10, 10))\n",
    "#     ax.imshow(img)\n",
    "\n",
    "seq = montage(\n",
    "    segmentation[::20, ::10, ::10], \n",
    "    grid_shape=(5, 5), \n",
    "    padding_width=10, \n",
    "    fill=255,\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(16, 16))\n",
    "ax.imshow(seq, cmap=plt.cm.gray)\n",
    "ax.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1b4659-c5e7-403a-9120-32ced30ec383",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE = datasets.cell_config()\n",
    "SEGMENTATION_FILE = datasets.example_segmentation_file()\n",
    "OBJECTS_FILE = datasets.example_track_objects_file()\n",
    "\n",
    "FEATURES = [\n",
    "    \"area\", \n",
    "    \"major_axis_length\", \n",
    "    \"minor_axis_length\", \n",
    "    \"orientation\", \n",
    "    \"solidity\"\n",
    "]\n",
    "\n",
    "objects = btrack.utils.segmentation_to_objects(\n",
    "    segmentation, \n",
    "    properties=tuple(FEATURES), \n",
    "    num_workers=4,  # parallelise this\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c602666f-948c-4638-8831-2712d29739cb",
   "metadata": {},
   "source": [
    "### Perform Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fea930-f8a1-47e9-97c2-6c46b6f251e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise a tracker session using a context manager\n",
    "with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "    # configure the tracker using a config file\n",
    "    tracker.configure(CONFIG_FILE)\n",
    "    tracker.max_search_radius = 50\n",
    "    tracker.tracking_updates = [\"MOTION\", \"VISUAL\"]\n",
    "    tracker.features = FEATURES\n",
    "\n",
    "    # append the objects to be tracked\n",
    "    tracker.append(objects)\n",
    "\n",
    "    # set the tracking volume\n",
    "    tracker.volume=((0, 1600), (0, 1200))\n",
    "\n",
    "    # track them (in interactive mode)\n",
    "    tracker.track(step_size=100)\n",
    "\n",
    "    # generate hypotheses and run the global optimizer\n",
    "    tracker.optimize()\n",
    "\n",
    "    # get the tracks in a format for napari visualization\n",
    "    data, properties, graph = tracker.to_napari()\n",
    "    \n",
    "    # store the tracks\n",
    "    tracks = tracker.tracks\n",
    "    \n",
    "    # store the configuration\n",
    "    cfg = tracker.configuration\n",
    "    \n",
    "    # export the track data \n",
    "    # tracker.export(\"tracks.h5\", obj_type=\"obj_type_1\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee60a74-3fc0-4b0f-9e42-29e5981f1819",
   "metadata": {},
   "source": [
    "# Run Napari to visualize tracks and segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231bb7a8-3148-403a-98aa-6072827682c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "viewer.add_image(\n",
    "    segmentation, \n",
    "    name=\"Segmentation\",\n",
    "    opacity=0.3,\n",
    ")\n",
    "\n",
    "viewer.add_image(\n",
    "    original_imgs, \n",
    "    name=\"Original Images\",\n",
    "    opacity=0.75,\n",
    ")\n",
    "\n",
    "# the track data from the tracker\n",
    "viewer.add_tracks(\n",
    "    data, \n",
    "    properties=properties, \n",
    "    graph=graph,\n",
    "    name=\"Tracks\", \n",
    "    blending=\"translucent\",\n",
    "    visible=True,\n",
    ")\n",
    "\n",
    "\n",
    "napari.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "czi_env",
   "language": "python",
   "name": "czi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
